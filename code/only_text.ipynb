{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c5536b-8df4-441a-bf78-d829af77688c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting multimodal-transformers\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/ab/7c839a1da28bd7dd74ef5a8b87d1e3e41225269bb4c7b05a68575809df7c/multimodal_transformers-0.4.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: accelerate>=0.29.3 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata~=7.1.0 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (7.1.0)\n",
      "Requirement already satisfied: networkx~=2.6.3 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (2.6.3)\n",
      "Requirement already satisfied: numpy~=1.26.4 in /environment/miniconda3/lib/python3.11/site-packages (from multimodal-transformers) (1.26.4)\n",
      "Requirement already satisfied: pandas~=2.2.2 in /environment/miniconda3/lib/python3.11/site-packages (from multimodal-transformers) (2.2.2)\n",
      "Requirement already satisfied: pytest~=7.2.2 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (7.2.2)\n",
      "Requirement already satisfied: sacremoses~=0.0.53 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (0.0.53)\n",
      "Requirement already satisfied: scikit-learn~=1.5.1 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy~=1.13.0 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (1.13.1)\n",
      "Requirement already satisfied: torch>=2.0.1 in /environment/miniconda3/lib/python3.11/site-packages (from multimodal-transformers) (2.2.2)\n",
      "Requirement already satisfied: transformers>=4.40.1 in /home/featurize/work/.local/lib/python3.11/site-packages (from multimodal-transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /environment/miniconda3/lib/python3.11/site-packages (from multimodal-transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /environment/miniconda3/lib/python3.11/site-packages (from accelerate>=0.29.3->multimodal-transformers) (23.2)\n",
      "Requirement already satisfied: psutil in /environment/miniconda3/lib/python3.11/site-packages (from accelerate>=0.29.3->multimodal-transformers) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /environment/miniconda3/lib/python3.11/site-packages (from accelerate>=0.29.3->multimodal-transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/featurize/work/.local/lib/python3.11/site-packages (from accelerate>=0.29.3->multimodal-transformers) (0.26.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/featurize/work/.local/lib/python3.11/site-packages (from accelerate>=0.29.3->multimodal-transformers) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/featurize/work/.local/lib/python3.11/site-packages (from importlib-metadata~=7.1.0->multimodal-transformers) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /environment/miniconda3/lib/python3.11/site-packages (from pandas~=2.2.2->multimodal-transformers) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /environment/miniconda3/lib/python3.11/site-packages (from pandas~=2.2.2->multimodal-transformers) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /environment/miniconda3/lib/python3.11/site-packages (from pandas~=2.2.2->multimodal-transformers) (2024.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /environment/miniconda3/lib/python3.11/site-packages (from pytest~=7.2.2->multimodal-transformers) (23.2.0)\n",
      "Requirement already satisfied: iniconfig in /home/featurize/work/.local/lib/python3.11/site-packages (from pytest~=7.2.2->multimodal-transformers) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /environment/miniconda3/lib/python3.11/site-packages (from pytest~=7.2.2->multimodal-transformers) (1.0.0)\n",
      "Requirement already satisfied: regex in /home/featurize/work/.local/lib/python3.11/site-packages (from sacremoses~=0.0.53->multimodal-transformers) (2024.9.11)\n",
      "Requirement already satisfied: six in /environment/miniconda3/lib/python3.11/site-packages (from sacremoses~=0.0.53->multimodal-transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/featurize/work/.local/lib/python3.11/site-packages (from sacremoses~=0.0.53->multimodal-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/featurize/work/.local/lib/python3.11/site-packages (from sacremoses~=0.0.53->multimodal-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/featurize/work/.local/lib/python3.11/site-packages (from scikit-learn~=1.5.1->multimodal-transformers) (3.5.0)\n",
      "Requirement already satisfied: filelock in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /environment/miniconda3/lib/python3.11/site-packages (from torch>=2.0.1->multimodal-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /environment/miniconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->multimodal-transformers) (12.4.127)\n",
      "Requirement already satisfied: requests in /environment/miniconda3/lib/python3.11/site-packages (from transformers>=4.40.1->multimodal-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/featurize/work/.local/lib/python3.11/site-packages (from transformers>=4.40.1->multimodal-transformers) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /environment/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=2.0.1->multimodal-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.40.1->multimodal-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.40.1->multimodal-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.40.1->multimodal-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.40.1->multimodal-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /environment/miniconda3/lib/python3.11/site-packages (from sympy->torch>=2.0.1->multimodal-transformers) (1.3.0)\n",
      "Installing collected packages: multimodal-transformers\n",
      "Successfully installed multimodal-transformers-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install multimodal-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32382d4-2263-4792-b959-55c6bdcde384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting datasets\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/3e/e58d4db4cfe71e3ed07d169af24db30cfd582e16f977378bd43fd7ec1998/datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m194.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/21/9ca93b84b92ef927814cb7ba37f0774a484c849d58f0b692b16af8eebcfb/pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m304.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m166.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/5d/acf5905c36149bbaec41ccf7f2b68814647347b72075ac0b1fe3022fdc73/tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m194.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/72/9256303f10e41ab004799a4aa74b80b3c5977d6383ae4550548b24bd1971/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m259.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b2/07/8cbb75d6cfbe8712d8f7f6a5615f083c6e710ab916b748fbb20373ddb142/multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m230.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /environment/miniconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (3.7.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/featurize/work/.local/lib/python3.11/site-packages (from datasets) (0.26.0)\n",
      "Requirement already satisfied: packaging in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /environment/miniconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m231.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /environment/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /environment/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /environment/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /environment/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, dill, multiprocess, datasets\n",
      "Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 tqdm-4.66.5 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b239f29-0832-470f-9a9c-2eb2bc6c9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openpyxl in /home/featurize/work/.local/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /home/featurize/work/.local/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9876cc3-ddb6-4fe8-bfd5-60ca62934a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650eb11-7256-467d-a0d1-ccb83c0d206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e53327-a2d4-4b39-945f-273eb124c9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82246e1-c4ff-4d4a-923d-fc495c91d866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-22 02:56:33.714305: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-22 02:56:33.724636: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 02:56:33.736761: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 02:56:33.740510: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 02:56:33.750091: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 02:56:34.886545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, Trainer, EvalPrediction, set_seed\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "import sys\n",
    "\n",
    "from multimodal_transformers.data import load_data_from_folder\n",
    "from multimodal_transformers.model import TabularConfig\n",
    "from multimodal_transformers.model import AutoModelWithTabular\n",
    "from multimodal_transformers.multimodal_arguments import (\n",
    "    ModelArguments,\n",
    "    MultimodalDataTrainingArguments,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "os.environ[\"COMET_MODE\"] = \"DISABLED\"\n",
    "# print(multimodal_transformers.getsitepackages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3f02ce-33b4-443b-84ec-6b157697330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/.local/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `COMET_MODE=DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234\n"
     ]
    }
   ],
   "source": [
    "text_cols = [\"GPT4O-Contribution\"]\n",
    "cat_cols =[]\n",
    "numerical_cols = [\"Hit_1pct\",'Hit_5pct','Hit_10pct','Atyp_10pct_Z','Atyp_Median_Z','Atyp_Pairs','C10','C5','C_f','Citation_Count','NCT_Count','NSF_Count','Newsfeed_Count','Patent_Count','Reference_Count','SB_B','SB_T','Team_Size','Tweet_Count','WSB_Cinf','WSB_sigma','cit_d','important_cit_per','ref_5_per','ref_avg_age','ref_cit_mean','ref_d','ref_median_age']\n",
    "column_info_dict = {\n",
    "    \"text_cols\": text_cols,\n",
    "    \"num_cols\": numerical_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"label_col\": \"B/NB\",\n",
    "    \"label_list\": [\"NB\", \"IB\", \"B\"],\n",
    "}\n",
    "model_args = ModelArguments(model_name_or_path=\"bert-base-uncased\")\n",
    "\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_path=\"./only_text\",\n",
    "    # combine_feat_method=\"text_only\",  weighted_feature_sum_on_transformer_cat_and_numerical_feats\n",
    "    combine_feat_method=\"text_only\",\n",
    "    column_info=column_info_dict,\n",
    "    task=\"classification\",\n",
    "    categorical_encode_type=None,\n",
    "    categorical_handle_na=True,\n",
    "    categorical_na_value=\"Unknown\",\n",
    "    ohe_handle_unknown=\"error\",\n",
    "    numerical_transformer_method='none',\n",
    "    numerical_handle_na=True,\n",
    "    numerical_how_handle_na=\"zero\",\n",
    ")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./only_text\",\n",
    "    logging_dir=\"./only_text/log\",\n",
    "    overwrite_output_dir=True,\n",
    "    #seed=42,\n",
    "    seed=1234,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=100,\n",
    "    evaluation_strategy=\"epoch\",  # 每个 epoch 进行评估\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,  # 加载最佳模型\n",
    "    metric_for_best_model='f1',  # 选择用于比较的指标\n",
    "    logging_steps=25,\n",
    "    eval_steps=250,\n",
    "    greater_is_better=True  # 选择的指标越大越好\n",
    ")\n",
    "print(training_args.seed)\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bee8649-4d5d-4573-9827-e18a26e7935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified tokenizer:  bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path_or_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    truncation=True,     # 自动截断超过 max_length 的序列\n",
    "    max_length=512,      # 设置最大序列长度为 512\n",
    "    padding='max_length'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9077e55f-80bf-42fe-acbd-0ccae10a3d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:multimodal_transformers.data.load_data:Text columns: ['GPT4O-Contribution']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: The paper titled \"Inheritance of Fruit Shape and Seed Size of Watermelon\" presents significant insights into the genetic mechanisms governing fruit morphology and seed dimensions in watermelon cultivars. Key contributions of this study include the following:\n",
      "\n",
      "1. **Genetic Control**: The study identifies the inheritance patterns of fruit shape (spherical and oval) and seed size (short and medium) in two different watermelon cultivars. It highlights the role of a single allele with incomplete dominance affecting the fruit shape and differentiates the genetic control of seed size through a dominant short seed gene (Ti) and a recessive medium seed gene (ti). This nuanced understanding aids in elucidating the complexities of watermelon genetics.\n",
      "\n",
      "2. **Methodological Advances**: The authors employ a quantitative approach to measure seed size, providing a more precise understanding compared to previous qualitative classifications. This methodological rigor allows for a clearer interpretation of genetic relationships and their effects on seed characteristics, establishing a new standard for assessing seed size in watermelon research.\n",
      "\n",
      "3. **Implications for Breeding**: By revealing the genetic pathways responsible for specific traits in these cultivars, the paper provides essential information that can be leveraged for breeding programs aimed at enhancing desirable fruit characteristics. This advancement has practical applications in agricultural practices and crop improvement strategies.\n",
      "\n",
      "4. **Comparative Analysis**: The paper situates its findings within the context of existing research, drawing comparisons with prior studies on seed size inheritance. This comparative angle emphasizes the variability in inheritance behavior depending on the genotypes involved, suggesting that research findings may not be universally applicable across different populations.\n",
      "\n",
      "5. **Knowledge Dissemination**: By documenting these findings, the paper contributes to the broader scientific community’s understanding of plant genetics and enhances collaboration among researchers exploring similar genetic traits across various plant species. Such contributions foster a cumulative body of knowledge that supports academic inquiry and practical applications in horticulture and agriculture.\n",
      "\n",
      "Overall, this study not only expands the current understanding of watermelon genetics but also sets a precedent for future research and cultivar development, ultimately promoting the dissemination of knowledge in the field of plant biology and agricultural science.\n",
      "INFO:multimodal_transformers.data.load_data:Text columns: ['GPT4O-Contribution']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: The paper titled \"Identification of Precipitates in Diffusion Zones Using the Electron Probe Microanalyzer\" presents significant innovations in the field of materials science, particularly in the analysis of precipitates formed during diffusion processes in intermetallic systems. Its key contributions are as follows:\n",
      "\n",
      "1. **Advanced Analytical Technique**: The paper showcases the capability of the electron probe microanalyzer (EPMA) in identifying and analyzing individual precipitates, which enhances the understanding of microstructural changes during diffusion.\n",
      "\n",
      "2. **Insight into Impurity Interactions**: By examining the interaction between diffusing metals (niobium and chromium) with impurity elements (carbon, nitrogen, oxygen, phosphorus, and sulfur), the study reveals the nature of precipitate formation—specifically, the identification of Nb₂S₅ in the Nb-Fe system and CrN₂ or Cr₂N₅ in the Cr-Fe system. This work highlights the complex role of impurities in modifying the properties and behaviors of metal systems.\n",
      "\n",
      "3. **Variability of Impurity Activity**: One of the groundbreaking findings is the demonstration that impurity activity varies depending on the diffusing metal atoms, offering critical insights for metallurgists and material scientists in tailoring properties for specific applications.\n",
      "\n",
      "4. **Implications for Material Design**: The knowledge gained from this study contributes significantly to the understanding of phase stability and mechanical properties in materials, which can influence future research and development in metallurgical engineering and materials design.\n",
      "\n",
      "Overall, this paper enhances the dissemination of knowledge by providing a methodological framework for the analysis of metal diffusion and precipitate formation, offering valuable insights into material properties that are crucial for advancing technology in various industrial applications.\n",
      "INFO:multimodal_transformers.data.load_data:Text columns: ['GPT4O-Contribution']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: The paper titled \"mdm2 expression is induced by wild type p53 activity\" contributes significantly to the understanding of the regulatory mechanisms involving the p53 and MDM2 proteins. Here are some of the key innovations and impacts on knowledge dissemination:\n",
      "\n",
      "1. **Identification of MDM2 as a p53 Target**: The study provides compelling evidence that the expression of the mdm2 gene is directly regulated by the wild-type p53 protein. This finding highlights the role of p53 not only as a crucial tumor suppressor but also as a transcription factor that can activate its own antagonist, MDM2, thus establishing an autoregulatory feedback loop.\n",
      "\n",
      "2. **Rapid Kinetics of MDM2 Induction**: The researchers documented that the induction of mdm2 occurs at the mRNA level with very rapid kinetics, suggesting that the regulatory mechanism is efficient and immediate. This rapid response emphasizes the significance of p53’s role in cellular stress responses and tumor suppression.\n",
      "\n",
      "3. **Protein-Protein Interactions**: The characterization of the enhanced complex formation between the t p53 and the p95 (MDM2) protein under specific temperature conditions provides insights into the dynamics of protein interactions crucial for understanding p53’s function and regulation.\n",
      "\n",
      "4. **Implications for Cancer Biology**: By detailing the interaction between p53 and MDM2, this research informs the ongoing development of cancer therapies targeting the p53-MDM2 axis. The discovery that MDM2 acts as a specific antagonist to p53 activity has implications for therapeutic strategies designed to stabilize p53 function in cancer cells.\n",
      "\n",
      "5. **Foundation for Future Research**: The findings presented in this study have paved the way for subsequent investigations into the intricacies of the p53 signaling pathway and its impact on apoptosis, cellular metabolism, and the broader landscape of oncogenesis.\n",
      "\n",
      "Overall, this paper not only advances the scientific understanding of p53 and MDM2 interactions but also emphasizes the importance of autoregulation in cellular signaling processes. It contributes to the foundation for future research in cancer biology and the development of novel therapeutic strategies, thus promoting the dissemination of knowledge in the field of molecular oncology.\n"
     ]
    }
   ],
   "source": [
    "# Get Datasets\n",
    "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
    "    data_args.data_path,\n",
    "    data_args.column_info[\"text_cols\"],\n",
    "    tokenizer,\n",
    "    label_col=data_args.column_info[\"label_col\"],\n",
    "    label_list=data_args.column_info[\"label_list\"],\n",
    "    categorical_encode_type = data_args.categorical_encode_type,\n",
    "    numerical_transformer_method = data_args.numerical_transformer_method,\n",
    "    categorical_cols=data_args.column_info[\"cat_cols\"],\n",
    "    numerical_cols=data_args.column_info[\"num_cols\"],\n",
    "    sep_text_token_str=tokenizer.sep_token,\n",
    "    max_token_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b92dd31-eb75-4ba1-980c-4e0b308230bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_dataset.labels))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871bec7e-4b7d-4770-b5b6-cc2b4d57287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "tabular_config = TabularConfig(\n",
    "    num_labels=num_labels,\n",
    "    #cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
    "    numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
    "    **vars(data_args)\n",
    ")\n",
    "config.tabular_config = tabular_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149c194e-fd72-4346-80b2-263ab20060ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertWithTabular were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'tabular_classifier.bias', 'tabular_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithTabular.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e95e1f1-77ce-4f11-898d-02b02a5f23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "\n",
    "def calc_classification_metrics(p: EvalPrediction):\n",
    "    predictions = p.predictions[0]\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "    pred_scores = softmax(predictions, axis=1)[:, 1]\n",
    "    labels = p.label_ids\n",
    "    if len(np.unique(labels)) == 2:  # binary classification\n",
    "        roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(labels, pred_scores)\n",
    "        fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "        fscore[np.isnan(fscore)] = 0\n",
    "        ix = np.argmax(fscore)\n",
    "        threshold = thresholds[ix].item()\n",
    "        pr_auc = auc(recalls, precisions)\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
    "        result = {\n",
    "            \"roc_auc\": roc_auc_pred_score,\n",
    "            \"threshold\": threshold,\n",
    "            \"pr_auc\": pr_auc,\n",
    "            \"recall\": recalls[ix].item(),\n",
    "            \"precision\": precisions[ix].item(),\n",
    "            \"f1\": fscore[ix].item(),\n",
    "            \"tn\": tn.item(),\n",
    "            \"fp\": fp.item(),\n",
    "            \"fn\": fn.item(),\n",
    "            \"tp\": tp.item(),\n",
    "        }\n",
    "    else:\n",
    "        # [None, 'micro', 'macro', 'weighted']\n",
    "        acc = (pred_labels == labels).mean()\n",
    "        f1 = f1_score(y_true=labels, y_pred=pred_labels, average='weighted')\n",
    "        result = {\n",
    "            \"acc\": acc,\n",
    "            \"f1\": f1,\n",
    "            \"acc_and_f1\": (acc + f1) / 2,\n",
    "            \"mcc\": matthews_corrcoef(labels, pred_labels),\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85e39661-53b0-4486-aa2e-f60421260754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # 3个评估周期内无改进则停止\n",
    "    early_stopping_threshold=0.0001  # 改进幅度必须超过1%\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=calc_classification_metrics,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f329563-ce42-4c7a-9402-e72f09e51d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='684' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 684/1800 08:32 < 13:58, 1.33 it/s, Epoch 38/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc And F1</th>\n",
       "      <th>Mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.574391</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.764756</td>\n",
       "      <td>0.782378</td>\n",
       "      <td>0.177183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>0.556956</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.743084</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>-0.003170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.521002</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.756362</td>\n",
       "      <td>0.785324</td>\n",
       "      <td>0.083594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.539887</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.765004</td>\n",
       "      <td>0.782502</td>\n",
       "      <td>0.176996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.602466</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.757148</td>\n",
       "      <td>0.778574</td>\n",
       "      <td>0.120472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.801611</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750281</td>\n",
       "      <td>0.785855</td>\n",
       "      <td>0.037760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.738897</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.777675</td>\n",
       "      <td>0.799552</td>\n",
       "      <td>0.211829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.847829</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.749029</td>\n",
       "      <td>0.778086</td>\n",
       "      <td>0.066122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.788418</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.767053</td>\n",
       "      <td>0.779955</td>\n",
       "      <td>0.181080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.965663</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.770612</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.166421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.843457</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.776760</td>\n",
       "      <td>0.802666</td>\n",
       "      <td>0.205339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.983983</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.773199</td>\n",
       "      <td>0.797314</td>\n",
       "      <td>0.199079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.952947</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.782839</td>\n",
       "      <td>0.798562</td>\n",
       "      <td>0.288974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.042844</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.800984</td>\n",
       "      <td>0.807635</td>\n",
       "      <td>0.375136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.178673</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.778882</td>\n",
       "      <td>0.796584</td>\n",
       "      <td>0.212348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.125818</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.805390</td>\n",
       "      <td>0.813409</td>\n",
       "      <td>0.378161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.199035</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812864</td>\n",
       "      <td>0.820718</td>\n",
       "      <td>0.387180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.238354</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.784241</td>\n",
       "      <td>0.784978</td>\n",
       "      <td>0.326292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.269389</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.799430</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.358831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.304914</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.796628</td>\n",
       "      <td>0.801886</td>\n",
       "      <td>0.334516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.421865</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.784203</td>\n",
       "      <td>0.781387</td>\n",
       "      <td>0.352061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.235274</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.810330</td>\n",
       "      <td>0.819451</td>\n",
       "      <td>0.405657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.255773</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812475</td>\n",
       "      <td>0.820523</td>\n",
       "      <td>0.416958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.285794</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.807871</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.388282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.302660</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.815209</td>\n",
       "      <td>0.821890</td>\n",
       "      <td>0.424473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.327005</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.816366</td>\n",
       "      <td>0.822469</td>\n",
       "      <td>0.421476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.333876</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.815709</td>\n",
       "      <td>0.822140</td>\n",
       "      <td>0.422893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.341305</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.819784</td>\n",
       "      <td>0.827749</td>\n",
       "      <td>0.450972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.348858</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.356981</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.364568</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.376147</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.383404</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.390685</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.396794</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.405154</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.412409</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>0.415093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.420838</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.813109</td>\n",
       "      <td>0.820840</td>\n",
       "      <td>0.413402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 15s, sys: 40.7 s, total: 7min 56s\n",
      "Wall time: 8min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=684, training_loss=0.09754397057756585, metrics={'train_runtime': 512.937, 'train_samples_per_second': 217.961, 'train_steps_per_second': 3.509, 'total_flos': 1.1178311164440576e+16, 'train_loss': 0.09754397057756585, 'epoch': 38.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b41f3d-6fb0-4b42-8e85-014c0a887b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 498 ms, sys: 8.5 ms, total: 507 ms\n",
      "Wall time: 504 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3413046598434448,\n",
       " 'eval_acc': 0.8357142857142857,\n",
       " 'eval_f1': 0.8197843858573471,\n",
       " 'eval_acc_and_f1': 0.8277493357858164,\n",
       " 'eval_mcc': 0.4509716964670214,\n",
       " 'eval_runtime': 0.4983,\n",
       " 'eval_samples_per_second': 280.959,\n",
       " 'eval_steps_per_second': 36.123,\n",
       " 'epoch': 38.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.evaluate(eval_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db5c79be-7649-4c3a-be4f-5b9cc2ee658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7929\n",
      "Precision: 0.8344\n",
      "Recall: 0.7929\n",
      "F1 Score: 0.8102\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 确保模型在 cuda:0 上\n",
    "model.to(device)\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "# 确保所有输入张量都在同一设备上\n",
    "# test_batch = {k: v.to(device) for k, v in test_batch.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        test_batch = {k: v.to(device) for k, v in test_batch.items()}\n",
    "        _, logits, classifier_outputs = model(\n",
    "            test_batch[\"input_ids\"],\n",
    "            attention_mask=test_batch[\"attention_mask\"],\n",
    "            # token_type_ids=test_batch[\"token_type_ids\"],\n",
    "            cat_feats=test_batch[\"cat_feats\"],\n",
    "            numerical_feats=test_batch[\"numerical_feats\"],\n",
    "        )\n",
    "        all_logits.append(logits)\n",
    "        labels = test_batch[\"labels\"].to(device)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "# 确保 labels 在同一设备上\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)  # 合并标签列表为一个张量\n",
    "\n",
    "# 计算预测类别\n",
    "predictions = all_logits.argmax(axis=1)\n",
    "\n",
    "# 计算指标\n",
    "accuracy = (predictions == all_labels).float().mean().item()\n",
    "precision = precision_score(all_labels.cpu(), predictions.cpu(), average='weighted')\n",
    "recall = recall_score(all_labels.cpu(), predictions.cpu(), average='weighted')\n",
    "f1 = f1_score(all_labels.cpu(), predictions.cpu(), average='weighted')\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2972d-b9ec-46b7-8a77-ddc4550e3efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
